{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "Gstilfvtr6GP",
        "u81nHo4Br8nw",
        "jLzz9bCasCxM",
        "Y-b8TjzJsW7J"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Gstilfvtr6GP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwyU11s4ELDu"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "seed_value = 44\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier"
      ],
      "metadata": {
        "id": "u81nHo4Br8nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, channels_img, features_d, num_classes, img_size):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
        "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
        "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
        "            self._block(features_d * 8, features_d * 16, 4, 2, 1),\n",
        "            nn.Conv2d(features_d * 16, num_classes, kernel_size=4, stride=2, padding=0),\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size,\n",
        "                stride,\n",
        "                padding,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels, affine=True),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x.squeeze(-1).squeeze(-1)\n"
      ],
      "metadata": {
        "id": "azOAuGW2FGp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "metadata": {
        "id": "tcoQoQqS-jvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiperparameters"
      ],
      "metadata": {
        "id": "73bxc_AxsOXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 128\n",
        "CHANNELS_IMG = 1\n",
        "NUM_CLASSES = 2\n",
        "NUM_EPOCHS = 15"
      ],
      "metadata": {
        "id": "S8IK7UGfIM-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on real data"
      ],
      "metadata": {
        "id": "oA8_aiEpsK1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(CHANNELS_IMG, 128, NUM_CLASSES, IMAGE_SIZE).to(device)\n",
        "initialize_weights(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_data_dir = '/gdrive/MyDrive/chest_xray/train'\n",
        "test_data_dir = '/gdrive/MyDrive/chest_xray/test'\n",
        "train_data = datasets.ImageFolder(train_data_dir, transform=transform)\n",
        "test_data = datasets.ImageFolder(test_data_dir, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0\n",
        "    for imgs, labels in trainloader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        avg_loss = running_loss/len(trainloader)\n",
        "        print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}] - Loss: {avg_loss:.4f}\")\n",
        "        losses.append(avg_loss)"
      ],
      "metadata": {
        "id": "K8qcCxm6FGdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "uoUspGaXsUCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Numer epoki\")\n",
        "plt.ylabel(\"Wartość funkcji straty\")\n",
        "plt.savefig('classifier_loss.eps', format='eps', dpi=1200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hUTHnqmJUuIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in testloader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy of the classifier on test data: {accuracy:.2f}%\")\n",
        "\n",
        "conf_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "TP = conf_mat[1, 1]\n",
        "TN = conf_mat[0, 0]\n",
        "FP = conf_mat[0, 1]\n",
        "FN = conf_mat[1, 0]\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Przewidziana etykieta')\n",
        "plt.ylabel('Prawdziwa etykieta')\n",
        "plt.savefig('classifier_conf_matrix.eps', format='eps', dpi=1200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PIoHEKE7atnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator code"
      ],
      "metadata": {
        "id": "Y-b8TjzJsW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, channels_noise, channels_img, features_g, num_classes,\n",
        "                 img_size, embed_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.net = nn.Sequential(\n",
        "            self._block(channels_noise + embed_size, features_g * 32, 4, 1, 0),\n",
        "            self._block(features_g * 32, features_g * 16, 4, 2, 1),\n",
        "            self._block(features_g * 16, features_g * 8, 4, 2, 1),\n",
        "            self._block(features_g * 8, features_g * 4, 4, 2, 1),\n",
        "            self._block(features_g * 4, features_g * 2, 4, 2, 1),\n",
        "            nn.ConvTranspose2d(\n",
        "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
        "            ),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.embed = nn.Embedding(num_classes, embed_size)\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size,\n",
        "                stride,\n",
        "                padding,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        embedding = self.embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        x = torch.cat([x, embedding], dim=1)\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "3L7eSr1owEdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 128\n",
        "CHANNELS_IMG = 1\n",
        "NUM_CLASSES = 2\n",
        "GEN_EMBEDDING = 100\n",
        "NOISE_DIM = 100\n",
        "FEATURES_GEN = 128"
      ],
      "metadata": {
        "id": "bFFSwPIawI54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMAGE_SIZE, GEN_EMBEDDING).to(device)\n",
        "loaded_gen.load_state_dict(torch.load('/gdrive/MyDrive/Magisterka/final_gan_model/generator_model.pth'))\n",
        "loaded_gen.eval()"
      ],
      "metadata": {
        "id": "7AEUrzTpwK1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking classifier trained on real data results with generated data"
      ],
      "metadata": {
        "id": "cAH-towLslim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(generator, num_images, class_label):\n",
        "    noise = torch.randn(num_images, NOISE_DIM, 1, 1).to(device)\n",
        "\n",
        "    labels = torch.full((num_images,), class_label, dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        images = generator(noise, labels).cpu().numpy()\n",
        "    return images\n",
        "\n",
        "healthy_images = generate_images(loaded_gen, 1000, 0)\n",
        "pneumonia_images = generate_images(loaded_gen, 1000, 1)"
      ],
      "metadata": {
        "id": "9gvPZYrdwPrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_images_tensor = torch.tensor(healthy_images).to(device)\n",
        "pneumonia_images_tensor = torch.tensor(pneumonia_images).to(device)\n",
        "\n",
        "healthy_predictions = torch.argmax(model(healthy_images_tensor), dim=1)\n",
        "pneumonia_predictions = torch.argmax(model(pneumonia_images_tensor), dim=1)\n",
        "\n",
        "correct_healthy = (healthy_predictions == 0).sum().item()\n",
        "correct_pneumonia = (pneumonia_predictions == 1).sum().item()\n",
        "\n",
        "print(f\"Poprawnie sklasyfikowane zdrowe obrazy: {correct_healthy}/{len(healthy_images)}\")\n",
        "print(f\"Poprawnie sklasyfikowane obrazy z zapaleniem płuc: {correct_pneumonia}/{len(pneumonia_images)}\")\n",
        "\n",
        "true_labels_healthy = [0] * len(healthy_images)\n",
        "true_labels_pneumonia = [1] * len(pneumonia_images)\n",
        "\n",
        "true_labels = true_labels_healthy + true_labels_pneumonia\n",
        "predicted_labels = list(healthy_predictions.cpu().numpy()) + list(pneumonia_predictions.cpu().numpy())\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "TP = conf_mat[1, 1]\n",
        "TN = conf_mat[0, 0]\n",
        "FP = conf_mat[0, 1]\n",
        "FN = conf_mat[1, 0]\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Przewidziana etykieta')\n",
        "plt.ylabel('Prawdziwa etykieta')\n",
        "plt.savefig('classifier_conf_matrix_for_test_generated.eps', format='eps', dpi=1200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "20gJvR-LwUY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lerning classifier on generated + real data"
      ],
      "metadata": {
        "id": "KEiqbTXSnlrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(CHANNELS_IMG, 128, NUM_CLASSES, IMAGE_SIZE).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_data_dir = '/gdrive/MyDrive/chest_xray/train'\n",
        "test_data_dir = '/gdrive/MyDrive/chest_xray/test'\n",
        "train_data = datasets.ImageFolder(train_data_dir, transform=transform)\n",
        "test_data = datasets.ImageFolder(test_data_dir, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "healthy_images = [img.squeeze(0) for img in healthy_images]\n",
        "pneumonia_images = [img.squeeze(0) for img in pneumonia_images]\n",
        "\n",
        "healthy_pil_images = [transforms.ToPILImage()(img) for img in healthy_images]\n",
        "pneumonia_pil_images = [transforms.ToPILImage()(img) for img in pneumonia_images]\n",
        "\n",
        "\n",
        "class GeneratedDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "generated_healthy_dataset = GeneratedDataset(healthy_pil_images, [0]*len(healthy_pil_images), transform)\n",
        "generated_pneumonia_dataset = GeneratedDataset(pneumonia_pil_images, [1]*len(pneumonia_pil_images), transform)\n",
        "\n",
        "combined_train_dataset = ConcatDataset([train_data, generated_healthy_dataset, generated_pneumonia_dataset])\n",
        "combined_trainloader = DataLoader(combined_train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0\n",
        "    for imgs, labels in combined_trainloader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        avg_loss = running_loss/len(combined_trainloader)\n",
        "        print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}] - Loss: {avg_loss:.4f}\")\n",
        "        losses.append(avg_loss)"
      ],
      "metadata": {
        "id": "aTgxdULFnsNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "QA4jqjhPaC-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Numer epoki\")\n",
        "plt.ylabel(\"Wartość funkcji straty\")\n",
        "plt.savefig('classifier_loss_2.eps', format='eps', dpi=1200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "876zkuvQkUFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in testloader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy of the classifier on test data: {accuracy:.2f}%\")\n",
        "\n",
        "conf_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "TP = conf_mat[1, 1]\n",
        "TN = conf_mat[0, 0]\n",
        "FP = conf_mat[0, 1]\n",
        "FN = conf_mat[1, 0]\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Przewidziana etykieta')\n",
        "plt.ylabel('Prawdziwa etykieta')\n",
        "plt.savefig('classifier_conf_matrix_learned_on_real_and_generated.eps', format='eps', dpi=1200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eK2k-uTNwybn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}