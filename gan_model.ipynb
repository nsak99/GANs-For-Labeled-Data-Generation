{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgc33uO6qLJt"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNKYZXBMRIbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83424578-18af-4ab3-99d6-b548961a11a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "from google.colab import drive\n",
        "from scipy.stats import entropy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.models import inception_v3\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "seed_value = 44\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
        "inception_model = inception_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WqgRr0AqQU4"
      },
      "source": [
        "# Discriminator and Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yFf9sDMRQwg"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels_img, features_d, num_classes, img_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Conv2d(channels_img+1, features_d, kernel_size=4, stride=2,\n",
        "                      padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
        "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
        "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
        "            self._block(features_d * 8, features_d * 16, 4, 2, 1),\n",
        "            nn.Conv2d(features_d * 16, 1, kernel_size=4, stride=2, padding=0),\n",
        "        )\n",
        "        self.embed = nn.Embedding(num_classes, img_size*img_size)\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size,\n",
        "                stride,\n",
        "                padding,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.InstanceNorm2d(out_channels, affine=True),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        embedding = self.embed(labels).view(labels.shape[0], 1, self.img_size,\n",
        "                                            self.img_size)\n",
        "        x = torch.cat([x, embedding], dim=1)\n",
        "        return self.disc(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, channels_noise, channels_img, features_g, num_classes,\n",
        "                 img_size, embed_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.net = nn.Sequential(\n",
        "            self._block(channels_noise + embed_size, features_g * 32, 4, 1, 0),\n",
        "            self._block(features_g * 32, features_g * 16, 4, 2, 1),\n",
        "            self._block(features_g * 16, features_g * 8, 4, 2, 1),\n",
        "            self._block(features_g * 8, features_g * 4, 4, 2, 1),\n",
        "            self._block(features_g * 4, features_g * 2, 4, 2, 1),\n",
        "            nn.ConvTranspose2d(\n",
        "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
        "            ),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.embed = nn.Embedding(num_classes, embed_size)\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size,\n",
        "                stride,\n",
        "                padding,\n",
        "                bias=False,\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        embedding = self.embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        x = torch.cat([x, embedding], dim=1)\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def gradient_penalty(critic, labels, real, fake, device):\n",
        "    BATCH_SIZE, C, H, W = real.shape\n",
        "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
        "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
        "\n",
        "    mixed_scores = critic(interpolated_images, labels)\n",
        "\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=interpolated_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores),\n",
        "        create_graph=True,\n",
        "        retain_graph=True)[0]\n",
        "\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
        "    return gradient_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XLlHEecqrZ-"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4VPYA7qqXMP"
      },
      "source": [
        "# Hiperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4_zwl8O4I8A"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 2e-4\n",
        "BATCH_SIZE = 128\n",
        "IMAGE_SIZE = 128\n",
        "CHANNELS_IMG = 1\n",
        "NUM_CLASSES = 2\n",
        "GEN_EMBEDDING = 100\n",
        "NOISE_DIM = 100\n",
        "NUM_EPOCHS = 100\n",
        "FEATURES_DISC = 128\n",
        "FEATURES_GEN = 128\n",
        "CRITIC_ITERATIONS = 5\n",
        "LAMBDA_GP = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuMLygZQqaXU"
      },
      "source": [
        "# BalancedBatchSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQl5txJQ35BC"
      },
      "outputs": [],
      "source": [
        "class BalancedBatchSampler(torch.utils.data.sampler.Sampler):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.indices_by_class = defaultdict(list)\n",
        "\n",
        "        for idx, (_, label) in enumerate(self.dataset):\n",
        "            self.indices_by_class[label].append(idx)\n",
        "\n",
        "        self.batches = self.generate_batches()\n",
        "        self.num_batches = len(self.batches)\n",
        "\n",
        "    def shuffle_indices_by_class(self):\n",
        "        for key in self.indices_by_class:\n",
        "            random.shuffle(self.indices_by_class[key])\n",
        "\n",
        "    def generate_batches(self):\n",
        "        batches = []\n",
        "        self.shuffle_indices_by_class()\n",
        "        num_batches = min(len(self.indices_by_class[0]), len(self.indices_by_class[1])) // (BATCH_SIZE // 2)\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch = []\n",
        "            batch.extend(self.indices_by_class[0][i * (BATCH_SIZE // 2):(i + 1) * (BATCH_SIZE // 2)])\n",
        "            batch.extend(self.indices_by_class[1][i * (BATCH_SIZE // 2):(i + 1) * (BATCH_SIZE // 2)])\n",
        "            batches.append(batch)\n",
        "\n",
        "        return batches\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.batches = self.generate_batches()\n",
        "        return iter(self.batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAO8fUbprLex"
      },
      "source": [
        "# FID & IS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x52mc-EUTayy"
      },
      "outputs": [],
      "source": [
        "def get_inception_features(images, model):\n",
        "    images = F.interpolate(images, size=(299, 299))\n",
        "    images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "    outputs = model(images)\n",
        "    if isinstance(outputs, tuple):\n",
        "        return outputs[0]\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def compute_fid(real_features, fake_features):\n",
        "    mu1, sigma1 = real_features.mean(0), np.cov(real_features, rowvar=False)\n",
        "    mu2, sigma2 = fake_features.mean(0), np.cov(fake_features, rowvar=False)\n",
        "    diff = mu1 - mu2\n",
        "\n",
        "    covmean, _ = scipy.linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if not np.isfinite(covmean).all():\n",
        "        offset = np.eye(sigma1.shape[0]) * 1e-6\n",
        "        covmean = scipy.linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "    if np.iscomplexobj(covmean):\n",
        "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "            m = np.max(np.abs(covmean.imag))\n",
        "            raise ValueError(\"Imaginary component {}\".format(m))\n",
        "        covmean = covmean.real\n",
        "    tr_covmean = np.trace(covmean)\n",
        "    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gORzsuLWqbKc"
      },
      "outputs": [],
      "source": [
        "def inception_score(imgs, inception_model, splits=10):\n",
        "    def get_preds(imgs):\n",
        "        imgs = torch.nn.functional.interpolate(imgs, size=(299, 299))\n",
        "        with torch.no_grad():\n",
        "            if imgs.shape[1] == 1:\n",
        "                imgs = imgs.repeat(1, 3, 1, 1)\n",
        "            outputs = inception_model(imgs)\n",
        "            return torch.nn.functional.softmax(outputs, dim=1).data.cpu().numpy()\n",
        "\n",
        "    scores = []\n",
        "    preds = get_preds(imgs)\n",
        "    n = len(preds)\n",
        "    for i in range(splits):\n",
        "        part = preds[(n // splits) * i : (n // splits) * (i + 1), :]\n",
        "        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "        kl = np.mean(np.sum(kl, 1))\n",
        "        scores.append(np.exp(kl))\n",
        "\n",
        "    return np.mean(scores), np.std(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrUoNd0rrUkg"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuaVwyJdpqT3"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_dir = '/gdrive/MyDrive/chest_xray/train'\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir, transform=transform)\n",
        "sampler = BalancedBatchSampler(train_data)\n",
        "dataloader = torch.utils.data.DataLoader(train_data, batch_sampler=sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jlxeugsvks-p"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul18tDRrTYua"
      },
      "outputs": [],
      "source": [
        "gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMAGE_SIZE, GEN_EMBEDDING).to(device)\n",
        "critic = Discriminator(CHANNELS_IMG, FEATURES_DISC, NUM_CLASSES, IMAGE_SIZE).to(device)\n",
        "initialize_weights(gen)\n",
        "initialize_weights(critic)\n",
        "\n",
        "opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
        "opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "fixed_noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
        "\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "step = 0\n",
        "\n",
        "gen.train()\n",
        "critic.train()\n",
        "\n",
        "D_losses = []\n",
        "G_losses = []\n",
        "Dx_values = []\n",
        "DGz_values = []\n",
        "FID_values = []\n",
        "IS_values = []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    epoch_D_losses = []\n",
        "    epoch_G_losses = []\n",
        "    epoch_Dx = []\n",
        "    epoch_DGz = []\n",
        "    epoch_FID = []\n",
        "    epoch_IS = []\n",
        "\n",
        "    for batch_idx, (real, labels) in enumerate(dataloader, start=1):\n",
        "        real = real.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        for _ in range(CRITIC_ITERATIONS):\n",
        "            noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
        "            fake = gen(noise, labels)\n",
        "            critic_real = critic(real, labels).reshape(-1)\n",
        "            critic_fake = critic(fake, labels).reshape(-1)\n",
        "\n",
        "            gp = gradient_penalty(critic, labels, real, fake, device=device)\n",
        "\n",
        "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP*gp\n",
        "            critic.zero_grad()\n",
        "            loss_critic.backward(retain_graph=True)\n",
        "            opt_critic.step()\n",
        "\n",
        "        critic_fake = critic(fake, labels).reshape(-1)\n",
        "        loss_gen = -torch.mean(critic_fake)\n",
        "        gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        epoch_D_losses.append(loss_critic.item())\n",
        "        epoch_Dx.append(critic_real.mean().item())\n",
        "\n",
        "        epoch_G_losses.append(loss_gen.item())\n",
        "        epoch_DGz.append(critic_fake.mean().item())\n",
        "\n",
        "        with torch.no_grad():\n",
        "            real_features = get_inception_features(real, inception_model).cpu().numpy()\n",
        "            fake_features = get_inception_features(fake, inception_model).cpu().numpy()\n",
        "\n",
        "            fid = compute_fid(real_features, fake_features)\n",
        "            epoch_FID.append(fid)\n",
        "\n",
        "            mean_is, std_is = inception_score(fake, inception_model)\n",
        "            epoch_IS.append(mean_is)\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
        "                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise, labels)\n",
        "\n",
        "                img_grid_real = torchvision.utils.make_grid(real[:9], normalize=True, nrow=3)\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake[:9], normalize=True, nrow=3)\n",
        "\n",
        "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
        "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
        "\n",
        "            step += 1\n",
        "\n",
        "    D_losses.append(sum(epoch_D_losses)/len(epoch_D_losses))\n",
        "    G_losses.append(sum(epoch_G_losses)/len(epoch_G_losses))\n",
        "    Dx_values.append(sum(epoch_Dx)/len(epoch_Dx))\n",
        "    DGz_values.append(sum(epoch_DGz)/len(epoch_DGz))\n",
        "\n",
        "    FID_values.append(sum(epoch_FID)/len(epoch_FID))\n",
        "    IS_values.append(sum(epoch_IS)/len(epoch_IS))\n",
        "\n",
        "\n",
        "    fig, axs = plt.subplots(3, 3, figsize=(6,6))\n",
        "    for ax, img in zip(axs.ravel(), fake):\n",
        "        ax.imshow(img[0].cpu().detach().numpy(), cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    if not os.path.exists('./generated'):\n",
        "        os.makedirs('./generated')\n",
        "    plt.savefig(f'generated/epoch_{epoch}.png')\n",
        "    plt.close()\n",
        "\n",
        "torch.save(gen.state_dict(), 'generator_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvz0A2imq87_"
      },
      "outputs": [],
      "source": [
        "scores = [D_losses, G_losses, Dx_values, DGz_values, FID_values, IS_values]\n",
        "\n",
        "if not os.path.exists('./results'):\n",
        "        os.makedirs('./results')\n",
        "\n",
        "def variable_name(var, namespace=globals()):\n",
        "    return [name for name, value in namespace.items() if value is var][0]\n",
        "\n",
        "for score in scores:\n",
        "    with open(f\"results/{variable_name(score)}.txt\", \"w\") as file:\n",
        "        for val in score:\n",
        "            file.write(f\"{val}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Z4VPYA7qqXMP"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}